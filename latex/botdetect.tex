% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,

\documentclass{acm_proc_article-sp}

\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}

\begin{document}

\title{An Irrational Agent Approach to Thwarting Existing Bot Detection Schemes in Social Games}

\numberofauthors{4}

\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Titus Barik\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh, NC USA}\\
	\email{tbarik@ncsu.edu}
% 2nd. author
\alignauthor
Brent Harrison\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh, NC USA}\\       
	\email{beharri5@ncsu.edu}
% 3rd. author
\and
\alignauthor 
David Roberts\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh, NC USA}\\
	\email{robertsd@csc.ncsu.edu}
%\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor 
Xuxian Jiang\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh NC, USA}\\
	\email{xjiang4@ncsu.edu}
}

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle

\begin{comment}

\begin{abstract}
Bots are a huge problem in online games. Current bot detection approaches they assume that people play differently form humans and that bots have deterministic behavior while actual people do not. Consequently, common approaches include low-level protocol inspection.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{bot detection, social games, mimic attacks, human observational proofs} % NOT required for Proceedings

\end{comment}

\section{Introduction}

Cheating is not a new concept in online games.~\cite{classification} In fact, it's been around ever since what is arguably the first commercial multi-player game published in 1986, Lucasfilms' Habitat for the Commodore 64. In Habitat, players disassembled the binary code to discover client-side only checks, thereby gaining an unfair advantage over other players in the game.~\cite{habitat}

Since then, many aspects in the landscape of online multi-player games have changed drastically, though their fundamentals principles have remained much the same. What is different today is that we are now witnessing an unprecedented level of cheating in online games through the use of bots, or automated player agents, that perform actions in the game without any human intervention whatsoever. One can speculate on the endless multitude of reasons for this proliferation: the porous boundaries between virtual and physical economics~\cite{preventbotitem}, the technical challenges of bot creation for their authors, the false premise under which players actually play (``the mangle of play'')~\cite{mangle}, or even the virtual Skinnerian game mechanics that are critically described by Jonathan Blow, creator of \textit{Braid}, as ``a form of [player] exploitation''~\cite{skinner}.

Regardless of the underlying causes, it is clear that game manufacturers want to eliminate the use of bots in their online environments by using bot detection algorithms that accurately classify human players from bots.

Currently, the most promising techniques in bot detection fall into the category of either human interactive or observational proofs. These proofs classify players as either bots or humans by targetting some of the fundamental differences between bots and human players. Interactive mechanisms, for instance, rely on explicit Turing tests (such as CAPTHAs), while observational mechanisms rely on a bot's patterned behavior or some other deterministic characteristic that is impossible to generate by human players, due to the inherent mental and physical limitations in humans.~\cite{preventbotitem} So far, these approaches have been effective in certain classes of games, including first-person shooters (FPS), as well as many dynamic and sufficiently rich massively-multiplayer online game (MMOG) environments.

Yet, these existing approaches conveniently assume that mimicking attacks, that is, bots that play like humans for purposes of evading bot detection, will continue to be difficult to implement and execute in practice. To our knowledge, this assumption has not actually been experimentally verified either qualitatively or quantitatively in this problem domain.

\begin{figure}
\centering
\includegraphics[width=3.2in]{scrabblesque.png}
\caption{Our Flash implementation of Scrabblesque, a variation of Scrabble that mimics the Words with Friends layout.}
\end{figure}

Consequently, our contribution in this paper is that it provides experimental evidence so that we can objectively evaluate the validity of these claims, in the problem space of social Web-based games. For this reason, we have taken the atypical approach of bot detection \textit{evasion} -- from that of the attacker's perspective -- whereas existing literature in the field takes the conventional defensive position. Concretely, we have developed a bot model that plays a variation of Scrabble (Zynga's Words with Friends), in a way that is statistically accurate and indistinguishable from that of human players with respect to several facets of human interaction commonly used in bot detection. These facets include click-behavior, mouse positioning, path movement, and timing.

At the very least, we hope our work in this area will initiate a contrarian line of research that serves to close the gap between human players and bots from a detection standpoint. Such a motivation may indeed seem nefarious until we consider the possibility that bot detection is in and of itself a perpetual arms race that only serves to treat the symptom of the problem, while ignoring the underlying root causes in game design that compel players to use bots in the very first place. We speculate on this idea in more detail in our discussion section.

\section{Related Work}

Existing bot detection approaches can be classified into two broad dimensions. The first dimension of bot detection contrasts human interactive proofs (HIPs) against passive human observational proofs (HOPs). The second dimension distinguishes the system on which the bot detection decision algorithm is performed: either on the player's local client machine or on the remote game server.

The idea of human interactive proofs, also referred to in the literature as reverse Turing tests (RTTs), mandatory human participation (MHP), or CAPTHAs, are an explicit means through which the system asks the user to perform a task that is relatively simple for a human player to solve, but difficult for a computer.~\cite{embedpoker} Such approaches have been successfully used to hinder bots in areas such as e-commerce and banking, online forums, free e-mail services, and online polls.

Unfortunately, the use HIPs present unique challenges in games. First, the HIP cannot be a one-time challenge, otherwise the player could simply solve the HIP and then activate the bot. But more importantly, the use of multiple HIPs are intrusive, interfere with the natural flow of the game (``out-of-band'' ~\cite{preventbotitem}), and disrupt immersive game experience.

Efforts have been proposed to minimize the disruption of a player's game experience through HIPs in a way that is seamless within the game, such as by integrating mini-game challenges~\cite{minigame}, or by adding random variations in key aspects the game, such as item locations. However, even the authors concede that this approach will not stop determined adversaries.~\cite{preventbotitem} From our perspective, the major limitation of these integrated approaches is that game authors must now shoulder an additional burden of having to envision content that does not necessarily create a better game experience for the player, in order to satisfy what is a completely orthogonal security requirement.

Presently, we are therefore compelled to dismiss the use of HIPs in games as impractical, and instead focus our efforts on passive, HOP approaches to bot detection through client-side and server-side mechanisms.

\subsection{Client-Side Approaches}

The developers of Habitat recognized that the backend ``shall not assume the validity of anything a player computer tells it'', a pragmatic piece of advice that remains useful even today.~\cite{habitat} Yet, a few of the proposed approaches bot detection continue to rely on a flawed assumption that the responses provided from a player's machine can be trusted.

Strictly software approaches such as Warden, an automated tool against bot programs for World of Warcraft, monitor the player's computer for suspicious programs.~\cite{serverside} PunkBuster, another anti-cheat software technology, offers similar capabilities by relying on client trust.~\cite{punk} Since the client machine is outside of the game manufacturer's control,  software-only approaches at the clients-side are easily defeated.~\cite{exploit}

An alternative client-side approach attempts to detect computationally modified or fabricated data by verifying that all input data comes from a physically present human input device (HID), but doing so requires additional hardware functionality to maintain trust. Similarly, specialized tamper-proof CAPTHA input devices have also been proposed. Even if such approaches can somehow maintain integrity across all paths in the computational chain, such requirements seem excessive and impractical, particularly for casual games.

Furthermore, the use of client-side approaches is limited to an even greater extent in social Web-based games, which run in a sandboxed environment, such as Java, HTML/JavaScript, or Flash. In these environments, the application may not even have the capability to install additional software at the operating system level, and their ability to monitor the operating system and other processes is limited by the security of the sandbox.

We must acknowledge that client-side approaches are ultimately doomed to fail, given that determined hackers are more than willing to design firmware and even hardware level countermeasures. Simply put, clients cannot be trusted.

With that said, we now turn our attention to the limitations of existing automatic server-side approaches, which do not rely on client trust.

\subsection{Server-Side Approaches}

Server-side approaches are more promising. These payload based detection approaches focus on discrepancies between that of human players and computer agents and identify bots during one or more game play sessions. The approaches in this area are incredibly diverse, though they focus on desktop MMORPGs rather than the more common browser-based games found in social networks such as Facebook. Though the data is often still collected on the client-side, we consider these approaches to be server-side if the data traces can be analyzed at a location that is different from the player's machine.

One approaches involves behavioral analysis with respect to action frequencies and action types, with the assumption that frequencies of particular actions will be higher for bots than those of known human players.~\cite{behavior}  Artificial neural networks have also been used to identify patterned movement or actions, which bots should exhibit.~\cite{ann}. Avatar movement trajectory is still another discriminator for bot detection.~\cite{trajectory}.

Like their client-side counterparts, user-input data, such as mouse speed and displacement, have also been used to differentiate human players from bots. While the data is collected on the client-server, the data itself can be sent to a remote server and analyzed server-side.~\cite{botcraft}

Certainly, these approaches have shown to be effective against current bots, but all of the existing approaches must concede that they are limited by the same underlying assumption: that bots have and will continue to have some characteristically identifiable differences than those of human players. 

Let us now examine this concession as a function of the evaluation metric for existing approaches. In ~\cite{scum}, the approach is considered successful if the ``developer has to sacrifice efficiency to achieve stealth''. In ~\cite{van2009step}, the authors believe that ``most bot programs have a very simple AI'' as the basis for their successful detection. 

Gianvecchio, et. al specifically address the issue of mimicking attacks, conceding that it could be done, ``but at the cost of significant time and efforts.'' They also argue that a further difficulty for bots, especially in highly dynamic environments, is that game bots must process complex visuals.~\cite{botcraft} Though we agree with their assessment for complex game spaces, we cannot rest on our laurels in this continuing arms race.

Indeed, this rationalization becomes the subject of some scrutiny when the problem space shifts to the context of Web-based social games, where we believe these issues to be far more tractable. In such Web-based social games, for example, the graphics elements are not particularly sophisticated in that they are based on sprites or tiles. The game mechanics are also relatively simple and consist of a smaller set of action choices than full-features MMOGs. Moreover, many of these games are either turn-based, asynchronous, or have repetitive game elements that do not require complex AI to process. In our opinion, these games are also the perfect test bed from which to begin the study of bot detection evasion.

\section{Methodology}

And though the literatures argues that human-like behavior is difficult to emulate, we are not aware of any research that has actually attempted to quantify this claim.

In this paper, we propose to do so. Let us now contrast these MMOG environment with that social games, such as PopCap's Bejeweled or Zuma, Zynga's FarmVille or Words with Friends. In this problem space, the bots may indeed have single AI algorithms, but the players themselves are asked to perform repetitive, and dare I say, automatic actions. For example, one activity in FarmVille requires that the player click multiple times throughout a virtual field to plant corn. In Words with Friends, a variation of Scrabble, the number of actions themselves are constrained due to the nature of the game.

This section describes our experimental setup. We begin by describing a system architecture, and our data collection and analysis procedures.

Are we missing a section here? I feel like we are.

\begin{comment}

\subsection{System Architecture}

Our experimental focused on a specific category of online games -- social games. We felt that much of the existing literature focused on massively multiplayer online games, but less attention has been paid to social games, such as those in social networks like Facebook.

Interestly, since social games are delivered through Web-based sandboxes (such as Java, HTML/JavaScript, or Flash), the technological sandbox serves to effectively limit client-based detection approach anyway.

We therefore created a Flash-based game, a variant of Scrabble which we internally call Scrabblesque. This Flash-based game provides the player with an experience that is similar to Zynga's Words with Friends, but instead of another player the opponent is simply a computer agent. The Flash-based game provides a full game experience, but also records the in-game actions of the player such as mouse click and unclick actions, mouse movement, and word selection. These in-game actions are then used to construct a player interaction model for our mimicking bot.

Since the focus is on player data collection, the artificial of the game itself was quite simple. The opponent did not itself have a rack; it simply used a dictionary along with the currently unallocated tiles to determine a word position. Despite the fact that the opponent did not have an optimal word selection, it routinely beat human opponents because of its fully-observable dictionary.

\subsection{Deployment}

This section describes our experimental setup. The game Scrabbleque was placed on our online server. Participants were recruited through different online forums and social networks, such as Facebook and Twitter.

\subsection{Bots}

We developed a deterministic bot to evaluate our agent. The deterministic bot simply clicks in the exact center of each tile. This is representative of the simpler tools use for bot creation, such as AutoIT.

We also used rudimentary path information. Though we did not actually check the trajectory of the paths themselves, we did check for the existance of a path.

\section{Results}

In this section, we analyze the data from our player traces and let you know what's happened.

\subsection{Mouse Locations}

Here, we have a heatmap of the mouse locations shown in different ways. As you can see, the heatmap is excellent and it shows that for most buttons, the player clicks near the center though not exactly. In fact, we can model the player using using lognormal distribution with a sigma of 0.3. Oh oh!

\subsection{Mouse Paths}

Mouse paths were much more difficult to characterize. But they are summarized in this section?

\subsection{Input Sensitivity}

Our version of Scrabblesque does not have require any keyboard input; it relies solely on mouse actions to perform all functions within the game. Unfortuunately, one might expect that there are differences between input devices. For instance, a traditional desktop optimal mouse would have different motion paths than that of a touchpad, trackball, or a red-dot on IBM keywords. A small percentage of users may even be touch-screen enabled, in which case they will have no path at all.

Because our Flash game does not have the capability to examine the actual hardware, we instead used unsupersived learning to classify the different behaviors of the player data. It was interesting. Here's what we found.

\subsection{Games as Research}

We believe that games provide a good means to collect data for research. Even simple games are easier to recruit participants for; the competitive nature of games and their entertainment value implicitly solicit people to play them. We also found it useful in our research to create a game that represents an already popular game. This is not to create competition with the commercial games, but rather, to allow players to play a game in an environment that they are already familiar with. We aim to minimize the hurdle of participating in research.

We envision that much our future work will continue to use online games to study player behavior, modeling, and other aspects of online game play as a result.

\section{Future Work}

In this paper, we spent our time and analyzed the bot detection approach by looking at mouse clicks with respect to location but not anything else. During our experiment, we did in fact however collect not only mouse clicks, but also paths, as well as higher-level actions such as which words were selected, rack rearrangements, and so on. This data can be used to create a more robust mimicking bot that evades more sophisticated bot detection algorithms.

Particularly, in the domain of player rational. As online poker games attempt to detect cheaters by determining whether their moves are optimal, a similar approach might be taken in a game like Scrabble. That is to say, if a player continually places optimal words on the board, or has sudden cognitive shifts in word selection (such as having several games of easy words and suddenly play optimal words), we can identify that the player is either not themself or they have installed bot software of some capacity.

We intentionally a choose a Flash-based social game as a starting point. We would like to investigate bot detection avoidance in more complex social games that have non-turn based elements or real-time elements, such as FarmVille or CityVille.

We hope that the test bed of Scrabble will continue to aid us in the development of more sophisticated bot detection approaches.

\section{Discussions}

What's there to discuss? Is this the end of online games. How is this different form Future Work? Certainly, we don't solve all of the problems. Desktop games continue to be a challenge because of their 

\section{Conclusions}

\end{comment}

%ACKNOWLEDGMENTS are optional
%\section{Acknowledgments}

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{botdetect}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!

\balancecolumns
% That's all folks!
\end{document}
