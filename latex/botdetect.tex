% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,

\documentclass{acm_proc_article-sp}

\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}

\begin{document}

% Problem of bot detection
% increasing in popularity
% Existing techniques 
% Hypothesize pixel leel creating detecting and evasive
% user study, click/input traces of clicks
% data insight into bot creation/evasion
%
%
% Conclusions:
%  armms/race another race leap frog
%  discentive of bots thorugh game mechanics
%  
% 

\title{A Spatial Approach to the Bot Arms Race in Social Games}

\numberofauthors{4}

\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Titus Barik\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh, NC USA}\\
	\email{tbarik@ncsu.edu}
% 2nd. author
\alignauthor
Brent Harrison\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh, NC USA}\\       
	\email{beharri5@ncsu.edu}
% 3rd. author
\and
\alignauthor 
David Roberts\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh, NC USA}\\
	\email{robertsd@csc.ncsu.edu}
%\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor 
Xuxian Jiang\\
	\affaddr{North Carolina State University}\\
	\affaddr{Raleigh NC, USA}\\
	\email{xjiang4@ncsu.edu}
}

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle

\begin{comment}

\begin{abstract}
Bots are a huge problem in online games. Current bot detection approaches they assume that people play differently form humans and that bots have deterministic behavior while actual people do not. Consequently, common approaches include low-level protocol inspection.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{bot detection, social games, mimic attacks, human observational proofs} % NOT required for Proceedings

\end{comment}

\section{Introduction}

While cheating is not a new concept in online games, the proliferation of bots, or automated player agents that perform actions without any human intervention, has become a cause for concern for game manufacturers. Existing approaches to bot detection struggle with a perpetual arms race, since whatever means are devised to detect bots can just as easiliy be used to evade bot detection once the approach is discovered by the bot author. We hypothesis that using pixel-level interactions in conjunction with a specific game interface leads to we we have termed an unique spatiotemporal signature. [We don't have a spatiotemporal signature at the moment, though -- oops. Need to think of how to reword this hypothesis. My original hypothesis was that mimicking attacks are much more tractable in the domain of social games because of their unique characteristics.]

To evaluate this hypothesis, we performed a user study in which we deloyed a word game that is representative in both the style and mechanics of social games that being commercial deployed today. The results of this study provide insight into the difficulties of bot detection using mouse positioning in the social game space.

Currently, the most promising techniques in bot detection fall into the category of either human interactive or observational proofs. These proofs classify players as either bots or humans by targetting some of the fundamental differences between bots and human players. Interactive mechanisms, for instance, rely on explicit Turing tests (such as CAPTHAs), while observational mechanisms rely on a bot's patterned behavior or some other deterministic characteristic that is impossible to generate by human players, due to the inherent mental and physical limitations in humans.~\cite{preventbotitem} So far, these approaches have been effective in certain classes of games, including first-person shooters (FPS), as well as many dynamic and sufficiently rich massively-multiplayer online game (MMOG) environments. [This paragraph is way too bulky for an introduction -- really just want to say HIP vs. HOP and that HOP is more effective more games, and work pretty well for complex MMO games].

Consequently, we instead focus on the emerging problem space of social games. We define a social game as an entirely Web-based game that is deployed within a social network. These environments present unique challenges for bot detection that are found in general MMOGs. First, social games run within a sandboxed Web-browser environment, limiting their ability to collect data about the machine on which they are running. Second, the game mechanisms of social games offer a different, though overlapping, set of incentives for the creation of bots. [What can I do with this? Efficiency is irrelevent for social games. The style of bots will be different.] Finally, because social games are generally more simplistic in both interaction style and graphical complexity, we believe that the effective approaches to bot detection in the MMOG problem space became tractical from bot authors in the social games space.


\begin{figure}
\centering
\includegraphics[width=3.2in]{scrabblesque.png}
\caption{Our Flash implementation of Scrabblesque, a variation of Scrabble that mimics the Words with Friends layout.}
\end{figure}

Our contribution in this paper is that it we provide empirical evidence that mouse positioning is normal with respect to the center of the button, which has previously only been tested in carefully controlled environments. We also demonstrate that the creation of bots that mimic humans, with respect to mouse positioning, is in fact a tractable problem for bot authors. As a result, social games will require novel approaches outside of those used in MMOGs to successfully detect bots and disincentivize their usage.

\section{Related Work}

Existing bot detection approaches can be classified into two broad dimensions. The first dimension of bot detection contrasts human interactive proofs (HIPs) against passive human observational proofs (HOPs). The second dimension distinguishes the system on which the bot detection decision algorithm is performed: either on the player's local client machine or on the remote game server.

The idea of human interactive proofs, also referred to in the literature as reverse Turing tests (RTTs), mandatory human participation (MHP), or CAPTHAs, are an explicit means through which the system asks the user to perform a task that is relatively simple for a human player to solve, but difficult for a computer.~\cite{embedpoker} Such approaches have been successfully used to hinder bots in areas such as e-commerce and banking, online forums, free e-mail services, and online polls.

Unfortunately, the use HIPs present unique challenges in games. First, the HIP cannot be a one-time challenge, otherwise the player could simply solve the HIP and then activate the bot. But more importantly, the use of multiple HIPs are intrusive, interfere with the natural flow of the game (``out-of-band'' ~\cite{preventbotitem}), and disrupt immersive game experience.

Efforts have been proposed to minimize the disruption of a player's game experience through HIPs in a way that is seamless within the game, such as by integrating mini-game challenges~\cite{minigame}, or by adding random variations in key aspects the game, such as item locations. However, even the authors concede that this approach will not stop determined adversaries.~\cite{preventbotitem} From our perspective, the major limitation of these integrated approaches is that game authors must now shoulder an additional burden of having to envision content that does not necessarily create a better game experience for the player, in order to satisfy what is a completely orthogonal security requirement.

Presently, we are therefore compelled to dismiss the use of HIPs in games as impractical, and instead focus our efforts on passive, HOP approaches to bot detection through client-side and server-side mechanisms.

\subsection{Client-Side Approaches}

[Mostly gut this -- even if it's true, it's meaningless for social games, since they can't do anything about it]

The developers of Habitat recognized that the backend ``shall not assume the validity of anything a player computer tells it'', a pragmatic piece of advice that remains useful even today.~\cite{habitat} Yet, a few of the proposed approaches bot detection continue to rely on a flawed assumption that the responses provided from a player's machine can be trusted.

Strictly software approaches such as Warden, an automated tool against bot programs for World of Warcraft, monitor the player's computer for suspicious programs.~\cite{serverside} PunkBuster, another anti-cheat software technology, offers similar capabilities by relying on client trust.~\cite{punk} Since the client machine is outside of the game manufacturer's control,  software-only approaches at the clients-side are easily defeated.~\cite{exploit}

An alternative client-side approach attempts to detect computationally modified or fabricated data by verifying that all input data comes from a physically present human input device (HID), but doing so requires additional hardware functionality to maintain trust. Similarly, specialized tamper-proof CAPTHA input devices have also been proposed. Even if such approaches can somehow maintain integrity across all paths in the computational chain, such requirements seem excessive and impractical, particularly for casual games.

Furthermore, the use of client-side approaches is limited to an even greater extent in social Web-based games, which run in a sandboxed environment, such as Java, HTML/JavaScript, or Flash. In these environments, the application may not even have the capability to install additional software at the operating system level, and their ability to monitor the operating system and other processes is limited by the security of the sandbox.

We must acknowledge that client-side approaches are ultimately doomed to fail, given that determined hackers are more than willing to design firmware and even hardware level countermeasures. Simply put, clients cannot be trusted.

With that said, we now turn our attention to the limitations of existing automatic server-side approaches, which do not rely on client trust.

\subsection{Server-Side Approaches}

Server-side approaches are more promising. These payload based detection approaches focus on discrepancies between that of human players and computer agents and identify bots during one or more game play sessions. The approaches in this area are incredibly diverse, though they focus on desktop MMORPGs rather than the more common browser-based games found in social networks such as Facebook. Though the data is often still collected on the client-side, we consider these approaches to be server-side if the data traces can be analyzed at a location that is different from the player's machine.

One approaches involves behavioral analysis with respect to action frequencies and action types, with the assumption that frequencies of particular actions will be higher for bots than those of known human players.~\cite{behavior}  Artificial neural networks have also been used to identify patterned movement or actions, which bots should exhibit.~\cite{ann}. Avatar movement trajectory is still another discriminator for bot detection.~\cite{trajectory}.

Like their client-side counterparts, user-input data, such as mouse speed and displacement, have also been used to differentiate human players from bots. While the data is collected on the client-server, the data itself can be sent to a remote server and analyzed server-side.~\cite{botcraft}

Certainly, these approaches have shown to be effective against current bots, but all of the existing approaches must concede that they are limited by the same underlying assumption: that bots have and will continue to have some characteristically identifiable differences than those of human players. 

Let us now examine this concession as a function of the evaluation metric for existing approaches. In ~\cite{scum}, the approach is considered successful if the ``developer has to sacrifice efficiency to achieve stealth''. In ~\cite{van2009step}, the authors believe that ``most bot programs have a very simple AI'' as the basis for their successful detection. 

Gianvecchio, et. al specifically address the issue of mimicking attacks, conceding that it could be done, ``but at the cost of significant time and efforts.'' They also argue that a further difficulty for bots, especially in highly dynamic environments, is that game bots must process complex visuals.~\cite{botcraft} Though we agree with their assessment for complex game spaces, we cannot rest on our laurels in this continuing arms race.

Indeed, this rationalization becomes the subject of some scrutiny when the problem space shifts to the context of Web-based social games, where we believe these issues to be far more tractable. In such Web-based social games, for example, the graphics elements are not particularly sophisticated in that they are based on sprites or tiles. The game mechanics are also relatively simple and consist of a smaller set of action choices than full-features MMOGs. Moreover, many of these games are either turn-based, asynchronous, or have repetitive game elements that do not require complex AI to process. In our opinion, these games are also the perfect test bed from which to begin the study of bot detection evasion.

\section{Methodology}

This section describes our experimental setup. We begin by describing the system architecture, followed by our data collection and analysis procedures.

[Need help with this].

We created a Flash-based game that is a variation of the popular game, Scrabble. Flash and Java are popular platforms for social game design. We also wanted to design a game that is respresentative of that of existing social games, so that our results could directly be applied to commercial games rather than academic lab environments. Finally, Flash is ubiqutous and well-supported, plus it can be deployed online.

We leveraged social networks by posting our research to various social networks and online communities. We used snowball sampling by relying on the sharing features of social networks in order to collect locate participants who were willing to play the game. We collected 423 game sessions. We cannot identify specifically how many players played the game, since a person who played at the game more than once at two different time periods would be treated as a different game session.


\subsection{System Architecture}

Our experimental focused on a specific category of online games -- social games. We felt that much of the existing literature focused on massively multiplayer online games, but less attention has been paid to social games, such as those in social networks like Facebook.

Interestly, since social games are delivered through Web-based sandboxes (such as Java, HTML/JavaScript, or Flash), the technological sandbox serves to effectively limit client-based detection approach anyway.

We therefore created a Flash-based game, a variant of Scrabble which we internally call Scrabblesque. This Flash-based game provides the player with an experience that is similar to Zynga's Words with Friends, but instead of another player the opponent is simply a computer agent. The Flash-based game provides a full game experience, but also records the in-game actions of the player such as mouse click and unclick actions, mouse movement, and word selection. These in-game actions are then used to construct a player interaction model for our mimicking bot.

Since the focus is on player data collection, the artificial of the game itself was quite simple. The opponent did not itself have a rack; it simply used a dictionary along with the currently unallocated tiles to determine a word position. Despite the fact that the opponent did not have an optimal word selection, it routinely beat human opponents because of its fully-observable dictionary.

\begin{comment}

\subsection{Deployment}

This section describes our experimental setup. The game Scrabbleque was placed on our online server. Participants were recruited through different online forums and social networks, such as Facebook and Twitter.

\subsection{Bots}

We developed a deterministic bot to evaluate our agent. The deterministic bot simply clicks in the exact center of each tile. This is representative of the simpler tools use for bot creation, such as AutoIT.

We also used rudimentary path information. Though we did not actually check the trajectory of the paths themselves, we did check for the existence of a path.

\section{Results}

In this section, we analyze the data from our player traces and let you know what's happened.

\subsection{Mouse Locations}

Here, we have a heatmap of the mouse locations shown in different ways. As you can see, the heatmap is excellent and it shows that for most buttons, the player clicks near the center though not exactly. In fact, we can model the player using using lognormal distribution with a sigma of 0.3. Oh oh!

\subsection{Mouse Paths}

Mouse paths were much more difficult to characterize. But they are summarized in this section?

\subsection{Input Sensitivity}

Our version of Scrabblesque does not have require any keyboard input; it relies solely on mouse actions to perform all functions within the game. Unfortuunately, one might expect that there are differences between input devices. For instance, a traditional desktop optimal mouse would have different motion paths than that of a touchpad, trackball, or a red-dot on IBM keywords. A small percentage of users may even be touch-screen enabled, in which case they will have no path at all.

Because our Flash game does not have the capability to examine the actual hardware, we instead used unsupersived learning to classify the different behaviors of the player data. It was interesting. Here's what we found.

[AIC, log log-likelihood]

\subsection{Games as Research}

We believe that games provide a good means to collect data for research. Even simple games are easier to recruit participants for; the competitive nature of games and their entertainment value implicitly solicit people to play them. We also found it useful in our research to create a game that represents an already popular game. This is not to create competition with the commercial games, but rather, to allow players to play a game in an environment that they are already familiar with. We aim to minimize the hurdle of participating in research.

We envision that much our future work will continue to use online games to study player behavior, modeling, and other aspects of online game play as a result.

\section{Future Work}

In this paper, we spent our time and analyzed the bot detection approach by looking at mouse clicks with respect to location but not anything else. During our experiment, we did in fact however collect not only mouse clicks, but also paths, as well as higher-level actions such as which words were selected, rack rearrangements, and so on. This data can be used to create a more robust mimicking bot that evades more sophisticated bot detection algorithms.

Particularly, in the domain of player rational. As online poker games attempt to detect cheaters by determining whether their moves are optimal, a similar approach might be taken in a game like Scrabble. That is to say, if a player continually places optimal words on the board, or has sudden cognitive shifts in word selection (such as having several games of easy words and suddenly play optimal words), we can identify that the player is either not themself or they have installed bot software of some capacity.

We intentionally a choose a Flash-based social game as a starting point. We would like to investigate bot detection avoidance in more complex social games that have non-turn based elements or real-time elements, such as FarmVille or CityVille.

We hope that the test bed of Scrabble will continue to aid us in the development of more sophisticated bot detection approaches.

\section{Discussions}

What's there to discuss? Is this the end of online games. How is this different form Future Work? Certainly, we don't solve all of the problems. Desktop games continue to be a challenge because of their 

\section{Conclusions}

\end{comment}

%ACKNOWLEDGMENTS are optional
%\section{Acknowledgments}

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{botdetect}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!

\balancecolumns
% That's all folks!
\end{document}
